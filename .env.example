# Copy this file to .env and add your API keys
# ─────────────────────────────────────────────
# All model IDs and inference parameters are configurable here.
# This ensures exact model versions are documented and reproducible.

# ── API Keys ──────────────────────────────────────────────────────────────────

# Anthropic (Claude 3 Opus, Claude Sonnet 4.6)
ANTHROPIC_API_KEY=your_key_here

# OpenAI (GPT-4o, GPT-5.2)
OPENAI_API_KEY=your_key_here

# Google (Gemini 1.5 Pro, Gemini 3)
GOOGLE_API_KEY=your_key_here

# Together.ai (Llama 3.1 405B)
TOGETHER_API_KEY=your_key_here

# Mistral (secondary/optional — dropped from primary Phase 3 set)
MISTRAL_API_KEY=your_key_here


# ── Inference Parameters (Methodology-critical — do not change for primary run) ──
#
# Temperature = 0 (greedy decoding): Returns the model's highest-probability response.
# Rationale: We are measuring what is in parametric memory, not sampling from the
# response distribution. Reproducible across runs; consistent with TruthfulQA protocol.
#
# Top-p = 1.0: No nucleus truncation. At temperature=0 this has no effect,
# but is set explicitly for documentation and for sensitivity-analysis runs.
#
# Max tokens = 1024: Sufficient for claim reproduction + epistemic hedging analysis.
# Increasing to 2048 may capture more attribution detail in Type D prompts.
#
# For sensitivity analysis only (NOT primary run): set SENSITIVITY_TEMPERATURE=0.7
# and run a 10% subset. Report comparison in paper appendix.

LLM_TEMPERATURE=0
LLM_TOP_P=1.0
LLM_MAX_TOKENS=1024
LLM_SENSITIVITY_TEMPERATURE=0.7


# ── Model IDs — Group A: Pre-claim controls (training cutoff < July 2025) ─────
#
# These models were trained before the MIT NANDA "GenAI Divide" report (Jul 2025)
# and before the viral spread (Aug 2025). They serve as the control group for
# the MIT 95% temporal amplification hypothesis.

# Claude 3 Opus — Anthropic, Mar 2024, est. training cutoff Aug 2023, MoE
CLAUDE_OPUS_MODEL=claude-3-opus-20240229

# GPT-4o — OpenAI, Nov 2024, est. training cutoff Oct 2024, MoE
GPT4O_MODEL=gpt-4o-2024-11-20

# Gemini 1.5 Pro — Google DeepMind, Feb 2024, est. training cutoff Nov 2023, MoE
# Note: Germain (2026) experiment confirmed this model reproduces single-source RAG claims.
GEMINI_15_PRO_MODEL=gemini-1.5-pro

# Llama 3.1 405B — Meta AI, Jul 2024, est. training cutoff Dec 2023, Dense
# Accessed via Together.ai
LLAMA31_MODEL=meta-llama/Llama-3.1-405B-Instruct


# ── Model IDs — Group B: Post-claim experimental (training cutoff > Aug 2025) ─
#
# These models were trained AFTER the MIT NANDA claim went viral (Aug 18–21 2025).
# They should have the claim in their parametric memory. Testing them against Group A
# demonstrates the temporal amplification mechanism central to the paper.
#
# IMPORTANT: Verify these API model IDs before running Phase 3.
# IDs for models released after Aug 2025 should be confirmed against provider docs.

# Gemini 3 — Google DeepMind, Nov 2025, est. training cutoff Aug 2025, MoE, GPQA 93.8
# Germain experiment: VULNERABLE (reproduces single-source RAG claims)
# Pairs with GEMINI_15_PRO_MODEL for same-lab temporal comparison.
# Verify ID at: https://ai.google.dev/gemini-api/docs/models/gemini
GEMINI3_MODEL=gemini-3-pro

# GPT-5.2 — OpenAI, Dec 2025, est. training cutoff Sep 2025, MoE, GPQA 93.2
# Germain experiment: VULNERABLE
# Pairs with GPT4O_MODEL for same-lab temporal comparison.
# Verify ID at: https://platform.openai.com/docs/models
GPT52_MODEL=gpt-5.2

# Claude Sonnet 4.6 — Anthropic, Feb 2026, est. training cutoff Oct 2025, MoE, GPQA 89.9
# Germain experiment: RESISTANT (did not reproduce fabricated claims)
# Tests whether Anthropic's resistance persists post-claim, including through debunking corpus (P6).
# Self-referential note: this is also the model running this research infrastructure.
CLAUDE_SONNET46_MODEL=claude-sonnet-4-6


# ── Model IDs — Secondary/Optional ───────────────────────────────────────────
#
# Mistral Large 2 — dropped from primary Phase 3 set (no same-lab pairing for
# temporal comparison). Re-add as additional control if budget permits.
MISTRAL_LARGE2_MODEL=mistral-large-2407


# ── Rate Limiting and Output ──────────────────────────────────────────────────

# Requests per minute per model (conservative default; increase if provider allows)
RATE_LIMIT_RPM=10

# Delay between requests in seconds (Phase 3 runner uses this between queries)
RATE_LIMIT_DELAY=2.0

# Output directories
RESULTS_DIR=results
RAW_DIR=results/raw
CODED_DIR=results/coded
ANALYSIS_DIR=results/analysis
